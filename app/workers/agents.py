# app/workers/agents.py
import asyncio
from app.core.base_worker import BaseWorker
from app.core.event_bus import bus, Topic
from app.models.protocol import TaskPayload
from app.tools.pubmed_client import ingest_pubmed
from app.tools.arxiv_client import ingest_arxiv
from app.tools.github_client import ingest_github
from app.tools.trials_client import ingest_trials
from app.tools.rag_query import query_rag
from app.agents.writer import generate_markdown_report
from app.tools.pdf_exporter import save_markdown_as_pdf
from app.core.state_manager import state_manager
from app.core.memory import task_memory

# 1. Planner Agent: é€‰æ‹©å’Œå†³å®šä»»åŠ¡çš„ä¸‹ä¸€ä¸ª Agentã€‚ï¼ˆç›®å‰æ˜¯é€ä¼ ï¼‰
class PlannerAgent(BaseWorker):
    def __init__(self):
        super().__init__(Topic.PLANNER, Topic.CRAWLER)

    def process(self, payload: TaskPayload) -> TaskPayload:
        # è¿™é‡Œæœªæ¥åš Planningï¼Œç°åœ¨ç›´æ¥é€ä¼ 
        topic = payload.topic
        print(f"ğŸ§  [Planner] è§„åˆ’ä»»åŠ¡: {topic}")
        # åˆå§‹åŒ–ä»»åŠ¡è®°å½•
        state_manager.init_task(payload.task_id, payload.topic, payload.params)

        # === è®°å¿†æ£€ç´¢ =============
        # å°è¯•å›å¿†æ˜¯å¦åšè¿‡ç±»ä¼¼ä»»åŠ¡
        past_knowledge = task_memory.recall_task(topic)
        if past_knowledge:
            print(f"[Planner] å‘ç°ç±»ä¼¼ä»»åŠ¡è®°å¿†: {past_knowledge['topic']}")
            print("[Planner] ç­–ç•¥è°ƒæ•´: è·³è¿‡æŠ“å–ï¼Œå¤ç”¨å†å²çŸ¥è¯†ã€‚")
            # å°†å†å²æ•°æ®æ³¨å…¥ Payload
            payload.data["rag_context"] = [{
                "content": f"ã€å†å²çŸ¥è¯†å¤ç”¨ã€‘\nä¹‹å‰çš„ç ”ç©¶æ€»ç»“ï¼š{past_knowledge['summary']}",
                "metadata": {"source": "Memory", "type": "history"}
            }]
            # ç›´æ¥å‘å¸ƒåˆ° Writer
            next_payload = payload.next_step("memory_hit")
            bus.publish(Topic.WRITER, next_payload.model_dump())
            return None # é˜»æ­¢åç»­æµç¨‹
        # ===========================
        return payload.next_step("crawling_started")

# 2. Crawler Agent: è´Ÿè´£å¹¶å‘æŠ“å–
class CrawlerAgent(BaseWorker):
    def __init__(self):
        super().__init__(Topic.CRAWLER, Topic.RAG)

    def process(self, payload: TaskPayload) -> TaskPayload:
        topic = payload.topic
        print(f"ğŸ•·ï¸ [Crawler] å¼€å§‹å¤šæºæŠ“å–: {topic}")

        async def run_crawlers():
            # å¹¶å‘æ‰§è¡Œ
            results = await asyncio.gather(
                ingest_pubmed(topic),
                ingest_arxiv(topic),
                ingest_github(topic, top_n=1),
                return_exceptions=True 
            )
            # è§£æç»“æœï¼Œç»Ÿè®¡æˆåŠŸ/å¤±è´¥
            sources = ["PubMed", "ArXiv", "GitHub"]
            status_report = {}
            
            for source, res in zip(sources, results):
                if isinstance(res, Exception):
                    print(f"âš ï¸ [Crawler] {source} æŠ“å–å¤±è´¥: {res}")
                    status_report[source] = "Failed"
                else:
                    print(f"âœ… [Crawler] {source} æŠ“å–æˆåŠŸï¼Œæ•°é‡: {res}")
                    status_report[source] = "Success"

            # å¤„ç† Trials (åŒæ­¥å‡½æ•°ï¼Œå•ç‹¬åŒ… try-except)
            try:
                ingest_trials(topic)
                status_report["Trials"] = "Success"
            except Exception as e:
                print(f"âš ï¸ [Crawler] Trials æŠ“å–å¤±è´¥: {e}")
                status_report["Trials"] = "Failed"

            return status_report
        
        # è¿è¡Œçˆ¬è™«
        status = asyncio.run(run_crawlers())
        # åªè¦ä¸æ˜¯å…¨éƒ¨å¤±è´¥ï¼Œå°±è®¤ä¸ºæ˜¯éƒ¨åˆ†æˆåŠŸ
        # å°†æŠ“å–çŠ¶æ€ä¼ é€’ç»™ä¸‹æ¸¸
        return payload.next_step("crawling_done", {"crawl_status": status})

# 3. RAG Agent: è´Ÿè´£æ£€ç´¢
class RagAgent(BaseWorker):
    def __init__(self):
        super().__init__(Topic.RAG, Topic.WRITER)

    def process(self, payload: TaskPayload) -> TaskPayload:
        topic = payload.topic
        print(f"ğŸ” [RAG] æ­£åœ¨æ£€ç´¢ä¸Šä¸‹æ–‡...")
        
        results = query_rag(topic, top_k=5)
        # å°†ç»“æœå­˜å…¥ data ä¼ é€’ç»™ Writer
        # æ³¨æ„ï¼šresults æ˜¯ dict åˆ—è¡¨ï¼Œå¯ä»¥ç›´æ¥åºåˆ—åŒ–
        
        return payload.next_step("rag_done", {"rag_context": results})

# 4. Writer Agent: ç”ŸæˆæŠ¥å‘Š
class WriterAgent(BaseWorker):
    def __init__(self):
        super().__init__(Topic.WRITER, None) # é“¾æ¡ç»ˆç‚¹ï¼Œä¸å†å‘å¸ƒ

    def process(self, payload: TaskPayload) -> TaskPayload:
        topic = payload.topic
        context = payload.data.get("rag_context", [])
        
        print(f"âœï¸ [Writer] æ­£åœ¨æ’°å†™æŠ¥å‘Š...")
        report = generate_markdown_report(topic, context)
        
        # ä¿å­˜æ–‡ä»¶
        task_id = payload.task_id
        md_path = f"report_{task_id}.md"
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(report)
            
        # å¯¼å‡º PDF
        try:
            pdf_path = save_markdown_as_pdf(task_id, report)
            print(f"ğŸ‰ [Writer] ä»»åŠ¡å®Œæˆï¼PDF: {pdf_path}")
        except Exception:
            print("âš ï¸ PDF ç”Ÿæˆå¤±è´¥ï¼Œä½† MD å·²ä¿å­˜")

        # === å­˜å…¥è®°å¿† ===
        # æå–æŠ¥å‘Šçš„å‰ 500 å­—ä½œä¸ºæ‘˜è¦å­˜å…¥è®°å¿†åº“
        summary = report[:500].replace("#", "").replace("*", "")
        task_memory.remember_task(
            topic=topic,
            summary=summary,
            artifact_path=pdf_path
        )
        print(f"ğŸ§  [Writer] å·²å°†æœ¬ä»»åŠ¡å­˜å…¥é•¿æœŸè®°å¿†åº“ã€‚")
        # ==============================
        return None # ç»“æŸ